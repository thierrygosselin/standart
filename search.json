[{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"coding-style","dir":"Articles","previous_headings":"","what":"Coding style","title":"Using standart to inspect your reduced genome sequences","text":"standart trying hard follow tidyverse style guide. Inside stardart, using parallel execution always use argument: parallel.core.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"dependencies","dir":"Articles","previous_headings":"Coding style","what":"Dependencies","title":"Using standart to inspect your reduced genome sequences","text":"Make sure latest R RStudio version installing stardart. package radiator nice vignette . Install stardart following instructions.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"quality-control","dir":"Articles","previous_headings":"Coding style","what":"Quality control","title":"Using standart to inspect your reduced genome sequences","text":"highly recommend running sequencing files (entire lane chip) software dedicated QC. bad sequencing, need go pipeline… FastQC. fastqcr R alternative.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"reads-length","dir":"Articles","previous_headings":"Coding style > Quality control","what":"reads length","title":"Using standart to inspect your reduced genome sequences","text":"using Illumina sequencing, chances 100 pb reads (SE RADseq). Ion Torrent, size highly variable determine optimal size cut reads length, pipeline using assembly requires . Note pipeline performs de novo assembly works better uniform read length. output FastQC FastQC output read length distribution. ’s difficult know many markers get depending read size. see relationship position nucleotide read overall quality. helpful determine want cut Illumina reads 80 90 pb. FastQC figure typical Ion Torrent sequencing chip sequence length distribution: Use standart figure generated standart shows number reads get depending maximum size threshold selected:  function : can use individual file entire chip lane. Function documentation: ?standart::reads_length_distribution Remember depending types file (individual entire lane/chip: Barcodes adapters might relationship observed figure. ’s uncommon see increasing adapters present increasing read size. Repetitive sequences, unique reads might impact results (see noise section ).","code":"size <- standart::reads_length_distribution(   fq.file = \"my-fastq.fastq.gz\",    with.future = TRUE,    parallel.core = 12L   )"},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"noise","dir":"Articles","previous_headings":"Coding style","what":"Noise reduction","title":"Using standart to inspect your reduced genome sequences","text":"Reducing noise individual FQ file really help speeding analysis. use 200 samples. Nothing new : Daniel Ilut explains pipeline (Ilut et al. 2014) function basically R… Jon Puritz’s dDocent data reduction step similar example. Praveen’s pipeline RADProc (Ravindran et al. 2019) use something similar. Metagenomic analysis pipeline step denoising data.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"visualization","dir":"Articles","previous_headings":"Coding style > Noise reduction","what":"Visualization","title":"Using standart to inspect your reduced genome sequences","text":"prefer Daniel Ilut way visualizing information. function stardart::read_depth_plot requires 1 FQ file (stacks process_radtags stackr::run_process_radtags) fast run. highlight read coverage groups distinct reads within sample. say distinct reads, reads exactly , mismatches. distinct reads putative allele.  4 read coverage groups shown: distinct reads low coverage (red):  reads likely sequencing errors uninformative polymorphisms (shared samples). disting reads target coverage (green): Usually represent around 80% reads FQ file. ’s safe coverage range start exploring data (open discussion). Lower threshold (default = 7): go low maybe 3 ? can’t escape , ’s tolerance call heterozygote true heterozygote. want minimum coverage reference alternative allele. Yes, can use population information lower threshold use fancy bayesian algorithm. Higher threshold: lot open discussion, ’s lower limit another group (orange, see description). Minus 1 bp. distinct reads high coverage > 1 read depth (yellow):  legitimate alleles high coverage. distinct unique reads high coverage (orange):  ’ll find paralogous sequences, transposable elements high copy number variants. run data: function generate plot shown write figure working directory, using sample name: -fq_hap_read_depth.png.","code":"read.plot <- standart::read_depth_plot(   fq.file = \"my-fq.fq.gz\",   min.coverage.fig = 7L, #default   parallel.core = parallel::detectCores() - 1 #default )"},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"faq","dir":"Articles","previous_headings":"Coding style > Noise reduction","what":"FAQ","title":"Using standart to inspect your reduced genome sequences","text":"run function samples ? Please don’t. use running entire dataset. ’s going fairly . Run couple samples. Based number reads (distribution), choose 1 sample: average, average average compare look figures produced.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"filtering","dir":"Articles","previous_headings":"Coding style > Noise reduction","what":"Filtering ?","title":"Using standart to inspect your reduced genome sequences","text":"Removing noise FQ files, ’s usually hot topic… Personally, less better ’s definitely case small projects. don’t think noise problem pipline like stacks. large projects, ’s something else, certainly huge bottleneck. generate de novo assembly 2000 samples generate catalog noise, cleaning data can represent weeks computation time shave project! test: 1. Clean FQ file Use sample just used read coverage groups, , clean standart::clean_fq. ’s fast run: generate: 2. Run de novo assembly pipeline Run de novo assembly pipeline (e.g. stacks stackr next step : mismatch threshold series (using stackr::run_ustacks). , use raw clean FQ files compare output… projects, less reads (cleaned FQ file) means: faster de novo assemblies (’ve seen 3 times faster). higher coverage de novo assembly steps stacks less repetitive stacks blacklisted lower number locus assembly artifacts (lors SNPs/locus, etc) similar heterozygosity homozygosity proportions mismathches plots almost always identical: showing can use Mismatch threshold (-M stacks ustacks) cleaned raw FQ files. faster catalog generation time, stacks cstacks stackr::run_cstacks step. DIFFERENCES downstream analysis (population structure, outlier detection, Fst, assignment, closekin). keep blacklisted sequences (fasta file) ? use Biostrings::countPattern function look TE sequences;) 3. Filtering entire dataset see big difference convince filtering way go, can easily piece code: Transfer cleaned files raw ones separate folder/sub-folder keep things tidy.","code":"clean.fq.name <- standart::clean_fq(   fq.file = \"my-fq.fq.gz\",    min.coverage.threshold = 2,    remove.unique.reads = TRUE, #default   write.blacklist.fasta = TRUE,   write.blacklist = FALSE, #default   parallel.core = parallel::detectCores() - 1, #default   verbose = TRUE #default   ) my-fq_cleaned.fq.gz # the cleaned fq file my-fq_blacklisted_reads.fasta.gz # a fasta file with blacklisted sequences... fq.to.clean <- list.files(path = \"04_process_radtags/\") names(fq.to.clean) <- fq.to.clean  clean.all <- purrr::map_df(   .x = fq.to.clean,    .f = standart::clean_fq,   min.coverage.threshold = 5,    remove.unique.reads = TRUE, #default   write.blacklist.fasta = TRUE,   write.blacklist = FALSE, #default   parallel.core = 12 )"},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"normalization","dir":"Articles","previous_headings":"Coding style","what":"Data normalization","title":"Using standart to inspect your reduced genome sequences","text":"Another hot topic, debate… stacks step called process_radtags, stackr run_process_radtags, looking distribution number reads per sample, might getting one distribution:  ideal world, want uniform distribution. translate good field wet-lab techniques: tissue sampling preservation extraction (robots ?) pipetting DNA quantification required techniques resulted similar sequenced information samples. ’re compare apples apples. :) skewed (left right) normal distribution, ’ll comparing apples … citrus. samples lower reads less loci usually less heterozygous loci. Similarly, samples higher number reads loci, heterozygous loci. ’s likely cause ? student prior wet-lab experience DNA extraction downstream step (e.g. library prep) data preservation issues: historical DNA, fragmented DNA, etc. skipping DNA quantification library QC steps Ok, ’s problem ? Potentially problems: ascertainment bias drive populations polymorphism discovery bias missing data patterns individual heterozygosity problems patterns downstream analysis impacted differences samples: artifactual biological ? Solutions ?","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"wet-lab-normalization","dir":"Articles","previous_headings":"Coding style > Data normalization","what":"1. Wet-lab normalization","title":"Using standart to inspect your reduced genome sequences","text":"basic steps: sequence samples look stats ’ve discussed go back wet-lab prepare new plate sequence pool lanes/chips look sequencing statistics repeat step continue pipeline ’m fan: Way many wet-lab steps. wet-lab important part. Everything gets exacerbated RADseq. ’m favor pooling lanes chips (day!). ’s really like working microsatelites.","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"bio-informatic-normalization","dir":"Articles","previous_headings":"Coding style > Data normalization","what":"2. Bio-informatic normalization","title":"Using standart to inspect your reduced genome sequences","text":"right start impossible, prefer normalization de demultiplexing step… example stackr::run_process_radtags. prerequisite enough sequencing material (reads) samples. tool? standart::normalize_reads function. Rarefaction fasq files sub-sampling reads de novo assembly alignment new: Community biodiversity ecologists well aware species accumulation curves obtained rarefaction (Sanders, 1968). rarefaction method guarantees samples weight analysis. Metagenomics community analyzing alpha diversity deal differing sample depth given diversity statistic using rarefaction. means taking random subset given size original sample (see mothur, Schloss et al. 2009). Molecular ecologists reasons, RADseq enthusiasts seems unaware concept, see (Hale et al. 2009; Kalinowski, 2004 Puncher et al. 2018). Keywords: rarefaction, sub-sampling, normalization, standardization, sample size correction. steps ? goal reduce variance number reads samples rarefaction/normalization conducted aon fq file stacks process_radtags removing noise. normalized replicates generated function randomly selecting reads (without replacement) samples choose number replicates (default: 3) manage replicates like replicates might (want replicates…). Read function documentation look example observations using rarefaction: replicates similar mismathches plots: showing can use Mismatch threshold (-M stacks ustacks) rarefied samples. better de novo assembly statistics individual population heterozygosity real biological signal, rarefaction doesn’t impact downstream analysis. heterozygosity driven sequencing bias, bioinformatic rarefaction took care problem.","code":"# To run this function, bioconductor's ShortRead package is necessary: BiocManager::install(\"ShortRead\")  # using defaults: standart::normalize_reads(path.samples = \"~/corals\")  # customizing the function: standart::normalize_reads(    project.info = \"project.info.corals.tsv\",    path.samples = \"04_process_radtags\",    sample.reads = 2000000,    number.replicates = 3,    random.seed = 3,    parallel.core = 12    )"},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"faq-1","dir":"Articles","previous_headings":"Coding style > Data normalization > 2. Bio-informatic normalization","what":"FAQ","title":"Using standart to inspect your reduced genome sequences","text":"doesn’t bother throw away valuable information samples high read numbers ? Absolutely ! information already lost: used stacks generate catalog filtered data keep markers x individuals /sampling sites/populations. step ’s either loose markers get missing data… ’s loss information information confirmed samples: ’s statistic problem ecologists well aware . loss reads intrinsic RADseq:  Don’t believe , inspect stacks, stackr RADseq pipeline log files… Rarefaction just another step, molecular ecologists used . check total read depth 1 sample bioinformatic steps. Compare numbers actual read number start pipeline. > 30% lucky!","code":""},{"path":"https://thierrygosselin.github.io/standart/articles/using_standart.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Using standart to inspect your reduced genome sequences","text":"Ilut, D., Nydam, M., Hare, M. (2014). Defining Loci Restriction-Based Reduced Representation Genomic Data Non model Species: Sources Bias Diagnostics Optimal Clustering BioMed Research International 2014(2), 1 9. https://dx.doi.org/10.1155/2014/675158 Rochette, N., Rivera‐Colón, ., Catchen, J. (2019). Stacks 2: Analytical methods paired‐end sequencing improve RADseq‐based population genomics. Molecular Ecology https://dx.doi.org/10.1111/mec.15253 Harvey, M., Judy, C., Seeholzer, G., Maley, J. (2015). Similarity thresholds used short read assembly reduce comparability population histories across species PeerJ 3(), e895. https://dx.doi.org/10.7717/peerj.895 Ravindran, P., Bentzen, P., Bradbury, ., Beiko, R. (2019). RADProc: computationally efficient de novo locus assembler population studies using RADseq data Molecular Ecology Resources 19(1), 272-282. https://dx.doi.org/10.1111/1755-0998.12954 Schloss, P.D., et al., Introducing mothur: Open-source, platform-independent, community-supported software describing comparing microbial communities. Appl Environ Microbiol, 2009. 75(23):7537-41. Sanders HL (1968) Marine benthic diversity: comparative study. American Naturalist 102: pp. 243–282 Hale et al. (2009) relative merits normalization rarefaction gene discovery sturgeons. BMC genomics, 10, 203. Kalinowski (2004) Counting Alleles Rarefaction. Conservation Genetics, 5, 539–543. Puncher et al. (2018) Molecular Ecology Resources, 44, 678.","code":""},{"path":"https://thierrygosselin.github.io/standart/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Thierry Gosselin. Author, maintainer.","code":""},{"path":"https://thierrygosselin.github.io/standart/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gosselin T (2025). standart: standart: solves common challenges genome reduction sequences quality control. R package version 0.0.0.1, https://thierrygosselin.github.io/standart/.","code":"@Manual{,   title = {standart: standart: solves the most common challenges of genome reduction sequences quality control},   author = {Thierry Gosselin},   year = {2025},   note = {R package version 0.0.0.1},   url = {https://thierrygosselin.github.io/standart/}, }"},{"path":"https://thierrygosselin.github.io/standart/index.html","id":"standart-","dir":"","previous_headings":"","what":"standart: solves the most common challenges of genome reduction sequences quality control","title":"standart: solves the most common challenges of genome reduction sequences quality control","text":"standart provides R functions help solve common quality control challenges genome reduction sequences (DArT, RADseq, GBS, etc). standart really shines projects requires consistency among sequencing runs samples animals large complicated genomes.","code":""},{"path":"https://thierrygosselin.github.io/standart/index.html","id":"who-is-it-for-","dir":"","previous_headings":"","what":"Who is it for ?","title":"standart: solves the most common challenges of genome reduction sequences quality control","text":"package currently developed projects CSIRO.","code":""},{"path":"https://thierrygosselin.github.io/standart/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"standart: solves the most common challenges of genome reduction sequences quality control","text":"can install development version standart like :","code":"if (!require(\"devtools\")) install.packages(\"devtools\") devtools::install_github(\"thierrygosselin/standart\") library(standart)"},{"path":"https://thierrygosselin.github.io/standart/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"standart: solves the most common challenges of genome reduction sequences quality control","text":"Reads/sequences counter length distribution. Read depth plot highlights read coverage groups. Distinct unique reads high coverage repetitive elements assembled locus usually paralogs, retrotransposons, transposable elements, etc. Noise reduction fastq cleaning. Data normalization/rarefaction remove reduce ascertainment bias driving populations polymorphism discovery bias, missing data patterns, individual heterozygosity problems patterns. Noise reduction normalization help answer question: differences samples: artifactual biological.","code":""},{"path":"https://thierrygosselin.github.io/standart/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"standart: solves the most common challenges of genome reduction sequences quality control","text":"Vignettes Computer setup troubleshooting github packages help RAD/DArTseq analysis","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/Exposition_pipe_operator.html","id":null,"dir":"Reference","previous_headings":"","what":"Exposition pipe-operator — %$%","title":"Exposition pipe-operator — %$%","text":"magrittr Exposition pipe-operator","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/Exposition_pipe_operator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exposition pipe-operator — %$%","text":"","code":"lhs %$% rhs"},{"path":"https://thierrygosselin.github.io/standart/reference/check_fq.html","id":null,"dir":"Reference","previous_headings":"","what":"check_fq — check_fq","title":"check_fq — check_fq","text":"Check weird fq UPPER CASE ending used","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/check_fq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"check_fq — check_fq","text":"","code":"check_fq(fq.files, parallel.core = parallel::detectCores() - 1)"},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq.html","id":null,"dir":"Reference","previous_headings":"","what":"Removes the noise of an individual fastq file — clean_fq","title":"Removes the noise of an individual fastq file — clean_fq","text":"function reads fastq file individual clean removing: unique reads high coverage (likely paralogs TE) distinct reads low coverage","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Removes the noise of an individual fastq file — clean_fq","text":"","code":"clean_fq(   fq.files,   paired.end = FALSE,   min.coverage.threshold = 2L,   max.coverage.threshold = \"high.coverage.unique.reads\",   remove.unique.reads = TRUE,   write.blacklist = TRUE,   write.blacklist.fasta = TRUE,   compress = FALSE,   output = \"08_stacks_results/03_cleaned_fq\",   parallel.core = parallel::detectCores() - 1 )"},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Removes the noise of an individual fastq file — clean_fq","text":"fq.files (character, path). path individual fastq file check. Default: fq.files = \"-sample.fq.gz\". paired.end (logical) files paired-end. Default: paired.end = FALSE. min.coverage.threshold (integer). Minimum coverage threshold. function remove distinct reads coverage <= threshold. turn , min.coverage.threshold = NULL 0L. Default: min.coverage.threshold = 2L. max.coverage.threshold (integer, character). Maximum coverage threshold. function remove distinct reads coverage >= threshold. turn , max.coverage.threshold = NULL. default, use starting depth high coverage unique reads observed. Default: max.coverage.threshold = \"high.coverage.unique.reads\". remove.unique.reads (logical). Remove distinct unique reads high coverage. Likely paralogs Transposable elements. Default: remove.unique.reads = TRUE. write.blacklist (logical). Write blacklisted reads file. Default: write.blacklist = TRUE. write.blacklist.fasta (logical). Write blacklisted reads fasta file. Default: write.blacklist.fasta = TRUE. compress (logical) compress output files. disk space, compress, way faster way write. Default: compress = FALSE. output (character, path) Write cleaned fq files specific directory. Default: output = \"08_stacks_results/03_cleaned_fq\". parallel.core (integer) Enable parallel execution number threads. Default: parallel.core = parallel::detectCores() - 1.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Removes the noise of an individual fastq file — clean_fq","text":"function returns cleaned fq file name sample -C appended filename.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Removes the noise of an individual fastq file — clean_fq","text":"coming soon, just try meantime...","code":""},{"path":[]},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq_filename.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_fq_filename — clean_fq_filename","title":"clean_fq_filename — clean_fq_filename","text":"Removes last part fq filename","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/clean_fq_filename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_fq_filename — clean_fq_filename","text":"","code":"clean_fq_filename(x)"},{"path":"https://thierrygosselin.github.io/standart/reference/compound_assignment_pipe_operator.html","id":null,"dir":"Reference","previous_headings":"","what":"compound assignment pipe operator — %<>%","title":"compound assignment pipe operator — %<>%","text":"magrittr compound assignment pipe operator","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/compound_assignment_pipe_operator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compound assignment pipe operator — %<>%","text":"","code":"lhs %<>% rhs"},{"path":"https://thierrygosselin.github.io/standart/reference/fq_file_type.html","id":null,"dir":"Reference","previous_headings":"","what":"fq_file_type — fq_file_type","title":"fq_file_type — fq_file_type","text":"Detect fq file type","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/fq_file_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fq_file_type — fq_file_type","text":"","code":"fq_file_type(x)"},{"path":"https://thierrygosselin.github.io/standart/reference/list_sample_file.html","id":null,"dir":"Reference","previous_headings":"","what":"list_sample_file — list_sample_file","title":"list_sample_file — list_sample_file","text":"List sample file folder","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/list_sample_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list_sample_file — list_sample_file","text":"","code":"list_sample_file(f, full.path = FALSE, recursive = FALSE, paired.end = FALSE)"},{"path":"https://thierrygosselin.github.io/standart/reference/n.html","id":null,"dir":"Reference","previous_headings":"","what":"The number of observations in the current group. — n","title":"The number of observations in the current group. — n","text":"Check dplyr","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The number of observations in the current group. — n","text":"","code":"n()"},{"path":"https://thierrygosselin.github.io/standart/reference/normalize_reads.html","id":null,"dir":"Reference","previous_headings":"","what":"Rarefaction of reads samples — normalize_reads","title":"Rarefaction of reads samples — normalize_reads","text":"Rarefaction fasq files sub-sampling reads de novo assembly alignment. normalization/standardization/sample size correction step allows check statistics increasing read numbers (e.g. heterozygous markers). easy way disentangle artifact biological signal caused varying read numbers across samples.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/normalize_reads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rarefaction of reads samples — normalize_reads","text":"","code":"normalize_reads(   project.info = NULL,   fq.files,   sample.reads = 1e+06,   number.replicates = 3,   random.seed = NULL,   parallel.core = parallel::detectCores() - 1 )"},{"path":"https://thierrygosselin.github.io/standart/reference/normalize_reads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rarefaction of reads samples — normalize_reads","text":"project.info (character, path, optional) using stackr pipeline, project info file created. file provides info stats generated stacks stackr. project info file updated new samples. project info filename appended _normalize. file end .tsv. project.info file provided, function look number reads fastq files take longer. Default: project.info = NULL. fq.files (character, path) Path folder containing samples normalize. sample.reads (integer) number reads pick randomly. Default: sample.reads = 1000000. number.replicates (interger) number samples generate. default, 20 samples folder, 100 new samples generated. Default: number.replicates = 5. random.seed (integer, optional) reproducibility, set integer used inside function requires randomness. default, random number generated printed appropriate output. Default: random.seed = NULL. parallel.core (optional) number core parallel programming. samples normalize sequentially treated replicates generated parallel. default, parallel.core = parallel::detectCores() - 1. number adjusted automatically number replicates.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/normalize_reads.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rarefaction of reads samples — normalize_reads","text":"fastq files \"-1\", \"-2\", \"...\" appended original name. project info file provided, new replicate samples info integrated file. modified project info file _normalize appended original filename.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/normalize_reads.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rarefaction of reads samples — normalize_reads","text":"","code":"if (FALSE) { # \\dontrun{ library(standart) # To run this function, bioconductor \\code{ShortRead} package is necessary: source(\"http://bioconductor.org/biocLite.R\") biocLite(\"ShortRead\") # Using OpenMP threads nthreads <- .Call(ShortRead:::.set_omp_threads, 1L) on.exit(.Call(ShortRead:::.set_omp_threads, nthreads)) # using defaults: standart::normalize_reads(fq.files = \"~/corals\")  # customizing the function: standart::normalize_reads(    project.info = \"project.info.corals.tsv\",    fq.files = \"~/corals\",    sample.reads = 2000000,    number.replicates = 5,    random.seed = 3,    parallel.core = 5)  # You then need to run stackr: run_ustacks, run_sstacks, run_tsv2bam, run_gstacks, run_populations # or equivalent if a reference genome. } # }"},{"path":"https://thierrygosselin.github.io/standart/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward-pipe operator — %>%","title":"Forward-pipe operator — %>%","text":"magrittr forward-pipe operator","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward-pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://thierrygosselin.github.io/standart/reference/read_count_one.html","id":null,"dir":"Reference","previous_headings":"","what":"read_count_one — read_count_one","title":"read_count_one — read_count_one","text":"count 1 fq file","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_count_one.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read_count_one — read_count_one","text":"","code":"read_count_one(fq.files, verbose = FALSE, p = NULL)"},{"path":"https://thierrygosselin.github.io/standart/reference/read_counter.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts the number of reads in samples — read_counter","title":"Counts the number of reads in samples — read_counter","text":"function counts number reads samples present specified folder. Useful info (e.g. generated stacks process_radtags), want check distribution number reads samples.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_counter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts the number of reads in samples — read_counter","text":"","code":"read_counter(   fq.files,   strata = NULL,   plot.reads = TRUE,   write = TRUE,   parallel.core = parallel::detectCores() - 1 )"},{"path":"https://thierrygosselin.github.io/standart/reference/read_counter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Counts the number of reads in samples — read_counter","text":"fq.files (character, path) Path folder containing 1 samples count reads. strata (optional) strata file tab delimited file 2 columns headers: INDIVIDUALS STRATA. STRATA column can hierarchical grouping. create strata file see individuals2strata. already run stacks data, strata file similar stacks population map file, make sure required column names (INDIVIDUALS STRATA). Note: Make sure fastq file names (without extension) match INDIVIDUALS column strata file. default, figures generated without strata grouping. Default: strata = NULL. plot.reads default plot.reads = TRUE, distribution boxplot figures generated written directory. write default write = TRUE, data frame read counts figures written working directory. parallel.core (optional) number core parallel computing. default: parallel.core = parallel::detectCores() - 1.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_counter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Counts the number of reads in samples — read_counter","text":"list data frame sample id number reads. option generate figures selected, list also returns 2 figures (see example )","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_counter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Counts the number of reads in samples — read_counter","text":"","code":"if (FALSE) { # \\dontrun{ library(standart) # To run this function, bioconductor \\code{ShortRead} package is necessary: BiocManager::install(\"ShortRead\")  # with defaults read.info <- standart::read_counter(fq.files = \"corals\")  # to extract info from the list reads = read.info$reads reads.distribution <- read.info$reads.distribution reads.boxplot <- read.info$reads.boxplot  # If the default figures saved were not good, save with new width and height # the histogram ggplot2::ggsave( filename = \"reads.distribution.pdf\", plot = reads.distribution, width = 15, height = 15, dpi = 600, units = \"cm\", useDingbats = FALSE, limitsize = FALSE)  # the boxplot ggplot2::ggsave( filename = \"reads.boxplot.pdf\", plot = reads.boxplot, width = 15, height = 15, dpi = 600, units = \"cm\", useDingbats = FALSE, limitsize = FALSE) } # }"},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a figure with the read depth groups — read_depth_plot","title":"Generate a figure with the read depth groups — read_depth_plot","text":"function reads fastq file individual generate figure read coverage groups.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a figure with the read depth groups — read_depth_plot","text":"","code":"read_depth_plot(   fq.file,   min.coverage.fig = 7L,   output = \"read_depth_plot\",   parallel.core = parallel::detectCores() - 1 )"},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a figure with the read depth groups — read_depth_plot","text":"fq.file (character, path). path individual fastq file check. Default: fq.file = \"-sample.fq.gz\". min.coverage.fig (integer). Minimum coverage used draw color figure. Default: min.coverage.fig = 7L. output (character, path) figure saved. Default: \"read_depth_plot\". parallel.core (integer) Enable parallel execution number threads. Default: parallel.core = parallel::detectCores() - 1.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a figure with the read depth groups — read_depth_plot","text":"function returns read depth groups plot.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a figure with the read depth groups — read_depth_plot","text":"4 read coverage groups shown: distinct reads low coverage (red): reads likely sequencing errors uninformative polymorphisms (shared samples). disting reads target coverage (green): Usually represent around 80% reads FQ file. ’s safe coverage range start exploring data (open discussion). Lower threshold (default = 7): can’t escape , ’s tolerance call heterozygote true heterozygote. want minimum coverage reference alternative allele. Yes, can use population information lower threshold use fancy bayesian algorithm. Higher threshold: lot open discussion, ’s lower limit another group (orange, see description). Minus 1 bp. distinct reads high coverage > 1 read depth (yellow): legitimate alleles high coverage. distinct unique reads high coverage (orange): repetitive elements assembled locus usually paralogs, retrotransposons, transposable elements, etc.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate a figure with the read depth groups — read_depth_plot","text":"Ilut, D., Nydam, M., Hare, M. (2014). Defining Loci Restriction-Based Reduced Representation Genomic Data Non model Species: Sources Bias Diagnostics Optimal Clustering BioMed Research International  2014. https://dx.doi.org/10.1155/2014/675158","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/read_depth_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a figure with the read depth groups — read_depth_plot","text":"","code":"if (FALSE) { # \\dontrun{ require(vroom) check.reads.depth.groups <- read_depth_plot(fq.file = \"my-sample.fq.gz\") } # }"},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate the read length distribution of a fastq file — reads_length_distribution","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"function reads fastq file individual, lane chip generate read length distribution help decide threshold cut reads specific length.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"","code":"reads_length_distribution(   fq.file,   parallel.core = parallel::detectCores() - 1,   with.future = FALSE )"},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"fq.file (character, path). path fastq file (individal, lane chip). Default: fq.file = \"-sample.fq.gz\". parallel.core (integer) Enable parallel execution number threads. Default: parallel.core = parallel::detectCores() - 1. .future (logical) TRUE use future package run code parallel. Set parallel.core number physical, logical, cores. See example . Default: .future = FALSE.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"function returns plot tibble potential reads length thresholds associated number reads.","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"coming soon, just try meantime...","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/reads_length_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate the read length distribution of a fastq file — reads_length_distribution","text":"","code":"if (FALSE) { # \\dontrun{ require(ShortRead) reads.length.info <- standart::reads_length_distribution(   fq.file = \"my-sample.fq.gz\")   # with future package to get faster results:  require(future)  require(listenv)  reads.length.info <- standart::reads_length_distribution(   fq.file = \"my-sample.fq.gz\",   with.future = TRUE   ) } # }"},{"path":"https://thierrygosselin.github.io/standart/reference/standart_future.html","id":null,"dir":"Reference","previous_headings":"","what":"radiator parallel function — standart_future","title":"radiator parallel function — standart_future","text":"Updating radiator use future","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/standart_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"radiator parallel function — standart_future","text":"","code":"standart_future(   .x,   .f,   flat.future = c(\"int\", \"chr\", \"dfr\", \"dfc\", \"walk\", \"drop\"),   split.vec = FALSE,   split.with = NULL,   split.chunks = 4L,   parallel.core = parallel::detectCores() - 1,   forking = FALSE,   ... )"},{"path":"https://thierrygosselin.github.io/standart/reference/standart_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"standart_normalize — standart_normalize","title":"standart_normalize — standart_normalize","text":"main normalize function","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/standart_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"standart_normalize — standart_normalize","text":"","code":"standart_normalize(   fq.to.normalize,   count.reads = FALSE,   number.replicates,   sample.reads,   parallel.core = parallel::detectCores() - 1 )"},{"path":"https://thierrygosselin.github.io/standart/reference/stats_standart.html","id":null,"dir":"Reference","previous_headings":"","what":"stats_standart — stats_standart","title":"stats_standart — stats_standart","text":"Generate useful stats","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/stats_standart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"stats_standart — stats_standart","text":"","code":"stats_standart(data, x, group.by = NULL, digits = NULL)"},{"path":"https://thierrygosselin.github.io/standart/reference/write_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"write_normalize — write_normalize","title":"write_normalize — write_normalize","text":"Write normalize fastq file","code":""},{"path":"https://thierrygosselin.github.io/standart/reference/write_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"write_normalize — write_normalize","text":"","code":"write_normalize(   number.replicates,   subsample.random,   fq.to.normalize,   sample.reads )"},{"path":"https://thierrygosselin.github.io/standart/news/index.html","id":"standart-0001-2025-03-24","dir":"Changelog","previous_headings":"","what":"standart 0.0.0.1 2025-03-24","title":"standart 0.0.0.1 2025-03-24","text":"standart R package creation","code":""}]
